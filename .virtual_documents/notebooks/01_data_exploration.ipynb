


!pip install ipywidgets tqdm > /dev/null 2>&1





import os
import torch
import cv2
import pandas as pd
import numpy as np
from glob import glob
from tqdm import tqdm
import joblib

import random

import matplotlib.pyplot as plt





print("PyTorch:", torch.__version__)
print("OpenCV:", cv2.__version__)





class CFG:
    verbose = 1  # Verbosity
    seed = 35  # Random seed
    preset = "efficientnetv2_b2_imagenet"  # Name of pretrained classifier
    image_size = [400, 300]  # Input image size
    epochs = 13 # Training epochs
    batch_size = 64  # Batch size
    lr_mode = "cos" # LR scheduler mode from one of "cos", "step", "exp"
    drop_remainder = True  # Drop incomplete batches
    num_classes = 6 # Number of classes in the dataset
    fold = 0 # Which fold to set as validation data
    class_names = ['Seizure', 'LPD', 'GPD', 'LRDA','GRDA', 'Other']
    label2name = dict(enumerate(class_names))
    name2label = {v:k for k, v in label2name.items()}


torch.manual_seed(CFG.seed)
random.seed(CFG.seed)
np.random.seed(CFG.seed)





BASE_PATH = "../data"

SPEC_DIR = "./tmp/dataset/hms-hbac"

# Make dirs to hold train test split data
os.makedirs(SPEC_DIR + '/train_spectrograms', exist_ok=True)
os.makedirs(SPEC_DIR + '/test_spectrograms', exist_ok=True)


# Train + Valid
df = pd.read_csv(f'{BASE_PATH}/train.csv')

df['eeg_path'] = f'{BASE_PATH}/train_eegs/'+df['eeg_id'].astype(str)+'.parquet'
df['spec_path'] = f'{BASE_PATH}/train_spectrograms/'+df['spectrogram_id'].astype(str)+'.parquet'
df['spec2_path'] = f'{SPEC_DIR}/train_spectrograms/'+df['spectrogram_id'].astype(str)+'.npy'
df['class_name'] = df.expert_consensus.copy()
df['class_label'] = df.expert_consensus.map(CFG.name2label)
display(df.head(2))

# Test
test_df = pd.read_csv(f'{BASE_PATH}/test.csv')
test_df['eeg_path'] = f'{BASE_PATH}/test_eegs/'+test_df['eeg_id'].astype(str)+'.parquet'
test_df['spec_path'] = f'{BASE_PATH}/test_spectrograms/'+test_df['spectrogram_id'].astype(str)+'.parquet'
test_df['spec2_path'] = f'{SPEC_DIR}/test_spectrograms/'+test_df['spectrogram_id'].astype(str)+'.npy'
display(test_df.head(2))


# Define a function to process a single eeg_id
def process_spec(spec_id, split="train"):
    spec_path = f"{BASE_PATH}/{split}_spectrograms/{spec_id}.parquet"
    spec = pd.read_parquet(spec_path)
    spec = spec.fillna(0).values[:, 1:].T # fill NaN values with 0, transpose for (Time, Freq) -> (Freq, Time)
    spec = spec.astype("float32")
    np.save(f"{SPEC_DIR}/{split}_spectrograms/{spec_id}.npy", spec)

# Get unique spec_ids of train and valid data
spec_ids = df["spectrogram_id"].unique()

# Parallelize the processing using joblib for training data
_ = joblib.Parallel(n_jobs=-1, backend="loky")(
    joblib.delayed(process_spec)(spec_id, "train")
    for spec_id in tqdm(spec_ids, total=len(spec_ids))
)

# Get unique spec_ids of test data
test_spec_ids = test_df["spectrogram_id"].unique()

# Parallelize the processing using joblib for test data
_ = joblib.Parallel(n_jobs=-1, backend="loky")(
    joblib.delayed(process_spec)(spec_id, "test")
    for spec_id in tqdm(test_spec_ids, total=len(test_spec_ids))
)


spec_path = f"{BASE_PATH}/train_spectrograms/{spec_ids[0]}.parquet"
spec = pd.read_parquet(spec_path)
print(spec.head())


spec_path = f"{BASE_PATH}/train_spectrograms/{spec_ids[0]}.parquet"
spec = pd.read_parquet(spec_path)
spec = spec.fillna(0).values[:, 1:].T
print(spec.shape)
print(spec)



spec_path = f"{BASE_PATH}/train_spectrograms/{spec_ids[0]}.parquet"
spec = pd.read_parquet(spec_path)
spec = spec.fillna(0).values[:, 1:].T
print(spec.shape)
print(spec)


spec = pd.read_parquet(spec_path)
spec = spec.fillna(0).values[:, 1:].T
print(f"Min value: {spec.min()}, Max value: {spec.max()}")



from torch.utils.data import Dataset








import torch.nn.functional as F


class EEGDataset(Dataset):
    def __init__(self, df, data_dir, mode="train", transform=None, augment=None):
        self.df = df
        self.data_dir = data_dir
        self.mode = mode
        self.transform = transform
        self.augment = augment

        self.spec_paths = self.df['spec2_path'].values
        if mode != "test":
            self.labels = self.df['class_label'].values

    def __len__(self):
        return len(self.df)

    def preprocess(self, spectrogram):
        """
        Apply log transformation, normalization, and enforce a consistent size.
        """
        # Clip the spectrogram to [400, 300] or pad it accordingly
        target_width = 300
        if spectrogram.shape[1] > target_width:
            spectrogram = spectrogram[:, :target_width]  # Trim to the target width
        else:
            pad_width = target_width - spectrogram.shape[1]
            spectrogram = np.pad(spectrogram, ((0, 0), (0, pad_width)), mode='constant')
    
        # Log transform to enhance smaller values and reduce large outliers
        spectrogram = np.clip(spectrogram, a_min=np.exp(-4.0), a_max=np.exp(8.0))  # avoid log(0)
        spectrogram = np.log(spectrogram)
        
        # Normalize to zero mean and unit variance
        spectrogram -= np.mean(spectrogram)
        spectrogram /= (np.std(spectrogram) + 1e-6)

        # Stack grayscale image into 3 channels for compatibility with ImageNet models
        spectrogram = np.stack([spectrogram] * 3, axis=-1)  # Shape will be (H, W, 3)
    
        return spectrogram

    def __getitem__(self, idx):
        if torch.is_tensor(idx):
            idx = idx.tolist()
        spec_path = self.spec_paths[idx]
        spectrogram = np.load(spec_path)
    
        # Apply preprocessing
        spectrogram = self.preprocess(spectrogram)
    
        # Apply any transformation if provided (e.g., resizing, augmentation)
        if self.transform:
            spectrogram = self.transform(spectrogram)
    
        # Convert to tensor if not already a tensor
        if not isinstance(spectrogram, torch.Tensor):
            spectrogram = torch.tensor(spectrogram, dtype=torch.float32).permute(2, 0, 1)  # (H, W, C) -> (C, H, W)
    
        # Apply augmentation if provided
        if self.augment and self.mode == "train":
            spectrogram = self.augment(spectrogram)
        
        if self.mode != "test":
            # One-hot encode labels
            label = F.one_hot(torch.tensor(self.labels[idx]), num_classes=len(self.df['class_label'].unique()))
            label = label.float()  # Convert to float for compatibility with certain losses like KL Divergence
            return spectrogram, label
        else:
            return spectrogram






import torchvision.transforms as transforms


transform = transforms.Compose([
    transforms.ToTensor(),
    transforms.Resize((400, 300))  # Resizing to a fixed size (height, width)
])





from torchvision.transforms import v2


augment = transforms.Compose([
    v2.MixUp(alpha = 1.0),
    transforms.RandomErasing(
        p=0.5,
        scale=(0.06, 0.10),
        ratio=(8, 12), # freq mask
        value='random',
        inplace=False
    ),
    transforms.RandomErasing(
        p=0.5,
        scale=(0.06, 0.10),
        ratio=(0.1, 0.5), # freq mask
        value='random',
        inplace=False
    )
])





train_dataset = EEGDataset(df=df, data_dir=f"{SPEC_DIR}/train_spectrograms", mode="train", transform=transform, augment=random_cutout)
test_dataset = SpectrogramDataset(df=test_df, data_dir=f"{SPEC_DIR}/test_spectrograms", mode="test")


from torch.utils.data import DataLoader


train_loader = DataLoader(train_dataset, batch_size=CFG.batch_size, shuffle=True)
test_loader = DataLoader(test_dataset, batch_size=CFG.batch_size, shuffle=False)


def visualize_batch(data_loader, num_samples=4):
    # Get the first batch from the DataLoader
    for spectrograms, labels in data_loader:
        fig, axes = plt.subplots(1, num_samples, figsize=(20, 5))
        
        for i in range(num_samples):
            ax = axes[i]
            # Extract the first channel (since all channels are identical after stacking)
            spec = spectrograms[i][0].numpy()  # Extract the first channel
            
            # Normalize the image for better color scaling
            spec -= spec.min()
            spec /= spec.max() + 1e-4
            
            # Convert one-hot encoded label to the class index
            label_index = torch.argmax(labels[i]).item()
            
            # Display the image with a colormap, adjusting the origin
            cax = ax.imshow(spec, aspect='auto', origin='lower', cmap='viridis')
            ax.set_title(f"Label: {CFG.label2name[label_index]}")
            ax.set_xlabel("Time")
            ax.set_ylabel("Frequency")
            fig.colorbar(cax, ax=ax)
        
        plt.tight_layout()
        plt.show()
        
        # Break after the first batch
        break


# Visualize the first few samples in the DataLoader
visualize_batch(train_loader, num_samples=4)






